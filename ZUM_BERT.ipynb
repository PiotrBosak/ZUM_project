{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HD-Ux9Li2daU",
    "outputId": "ce259506-b898-4850-cb83-9a03253d4604"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLmzrX6a2ilO",
    "outputId": "f3e73687-5168-45ab-d136-bc4ee1c94fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /home/piotrzab/anaconda3/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: gensim==4.3.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (4.3.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from gensim==4.3.1) (1.10.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from gensim==4.3.1) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from gensim==4.3.1) (1.23.5)\n",
      "Requirement already satisfied: fasttext in /home/piotrzab/anaconda3/lib/python3.10/site-packages (0.9.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from fasttext) (2.10.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from fasttext) (65.6.3)\n",
      "Requirement already satisfied: numpy in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from fasttext) (1.23.5)\n",
      "Requirement already satisfied: tensorflow in /home/piotrzab/anaconda3/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.54.2)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (23.5.9)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.4.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (4.23.1)\n",
      "Requirement already satisfied: setuptools in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.18.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode\n",
    "!pip install gensim==4.3.1\n",
    "!pip install fasttext\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RSmCtEOa2pI6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 22:08:53.659341: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-24 22:08:53.661366: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-24 22:08:53.691048: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-24 22:08:53.691678: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 22:08:54.365338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import re\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "from re import sub\n",
    "from time import time \n",
    "from unidecode import unidecode\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import pad_sequences, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sz5UE5so29dw"
   },
   "outputs": [],
   "source": [
    "#data loading\n",
    "colnames=['comment'] \n",
    "hiphop = pd.read_csv(\"hiphopheads.csv\", on_bad_lines='skip',engine='python', header = None, names = colnames)\n",
    "jazz = pd.read_csv(\"jazz.csv\", on_bad_lines='skip',engine='python', header = None, names = colnames)\n",
    "punk = pd.read_csv(\"punk.csv\", on_bad_lines='skip',engine='python', header = None, names = colnames)\n",
    "metal = pd.read_csv(\"metal.csv\", on_bad_lines='skip',engine='python', header = None, names = colnames)\n",
    "classical = pd.read_csv(\"classicalmusic.csv\", on_bad_lines='skip',engine='python', header = None, names = colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k4FMtFVB3UBi"
   },
   "outputs": [],
   "source": [
    "\n",
    "# training BERT takes significantly more time for larger datasets.\n",
    "# We train BERT on fewer rows.\n",
    "\n",
    "fileList2 = []\n",
    "#fileList2.append(hiphop.head(30000))\n",
    "fileList2.append(jazz.sample(2000))\n",
    "#fileList2.append(punk.head(10000))\n",
    "fileList2.append(metal.sample(2000))\n",
    "#fileList2.append(classical.head(250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrAVKuL78QjQ",
    "outputId": "e3ff1a2a-9915-4feb-9589-11e95cc89efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                                                       comment\n",
      "t1_jdzmrpo   Breathless\\r -Kenny G\\n\\nI really hate quite a...\n",
      "t1_j66jw2y   I just discovered them. I cannot stop listenin...\n",
      "t1_j118cx5   That is one of the several reasons I posted th...\n",
      "t1_j3oqeev                                        Oh heck yes!\n",
      "t1_jcs5vay                      Sam Wilkes - Live on the Green\n",
      "...                                                        ...\n",
      "t1_j0x2fxt                                        Fantastic!!!\n",
      "t1_i9he4n9   More of the latter but has some heavier elemen...\n",
      "t1_i3ke1tl   I’m typically not into Tech Death, but my old ...\n",
      "*I am a bot   and this action was performed automatically. ...\n",
      "t1_j90e412   I saw Revocation with support from Goatwhore, ...\n",
      "\n",
      "[3036 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "merge = pd.concat(fileList2)\n",
    "# We remove lines longer than 500\n",
    "merge = merge[merge['comment'].str.len()<500]\n",
    "\n",
    "fileList = []\n",
    "fileList.append(merge)\n",
    "\n",
    "print(type(merge))\n",
    "print(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vDl9d48N7rwY"
   },
   "outputs": [],
   "source": [
    "def text_to_word_list(text, remove_polish_letters):\n",
    "    ''' Pre process and convert texts to a list of words \n",
    "    method inspired by method from eliorc github repo: https://github.com/eliorc/Medium/blob/master/MaLSTM.ipynb'''\n",
    "    text = remove_polish_letters(text)\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
    "    text = sub(r\"\\+\", \"\", text)\n",
    "    text = sub(r\",\", \"\", text)\n",
    "    text = sub(r\"\\.\", \"\", text)\n",
    "    text = sub(r\"!\", \"\", text)\n",
    "    text = sub(r\"\\?\", \"\", text)\n",
    "    text = sub(r\"'\", \"\", text)\n",
    "    text = sub(r\":\", \"\", text)\n",
    "    text = sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g4pZRhlWAnD3"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "alRtjwRHD8W9"
   },
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.title.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nwsid-aLEDAO"
   },
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UtjxuP76OhG2"
   },
   "outputs": [],
   "source": [
    "predictedList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahoFjAbU3gy0",
    "outputId": "21071022-62c9-4f3e-ba45-2ec4bed17023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.0 mins\n",
      "Time to train the model: 0.05 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_550078/2054725627.py:51: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n",
      "/home/piotrzab/anaconda3/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def divide_to_parts(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "for file_ in fileList:\n",
    "  parts = divide_to_parts(file_.comment, 3000)    \n",
    "  file_['rate'] = 1\n",
    "  file_cleaned = file_.dropna().drop_duplicates().reset_index(drop=True).rename(columns={'comment':'title'})\n",
    "  file_cleaned = file_cleaned[file_cleaned.rate!=0]\n",
    "  file_cleaned.rate.value_counts()/len(file_cleaned)\n",
    "\n",
    "  file_cleaned.title = file_cleaned.title.apply(lambda x: text_to_word_list(x, unidecode))\n",
    "  file_model = file_cleaned.copy()\n",
    "  file_model = file_model[file_model.title.str.len()>1]\n",
    "\n",
    "\n",
    "  parts = divide_to_parts(file_model.title, 3000)\n",
    "  for part in parts:    \n",
    "    #Detect bigrams with gensim's Phraser module.\n",
    "    sent = [row for row in part]\n",
    "    phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = bigram[sent]\n",
    "\n",
    "    #word embeddings with CBOW word2vec algorithm found in gensim module\n",
    "    w2v_model = Word2Vec(min_count=3,\n",
    "                      window=4,\n",
    "                      vector_size=300,\n",
    "                      sample=1e-5, \n",
    "                      alpha=0.03, \n",
    "                      min_alpha=0.0007, \n",
    "                      negative=20,\n",
    "                      workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "    print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    w2v_model.train(sentences,\n",
    "                    total_examples=w2v_model.corpus_count,\n",
    "                    epochs=30,\n",
    "                    report_delay=1)\n",
    "\n",
    "    print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "    w2v_model.init_sims(replace=True)\n",
    "\n",
    "\n",
    "    w2v_model.save(\"word2vec.model\")\n",
    "    \n",
    "    file_export = file_model.copy()\n",
    "    file_export['old_title'] = file_export.title\n",
    "    file_export.old_title = file_export.old_title.str.join(' ')\n",
    "    file_export.title = file_export.title.apply(lambda x: ' '.join(bigram[x]))\n",
    "    file_export.rate = file_export.rate.astype('int8')\n",
    "\n",
    "    file_export[['title', 'rate']].to_csv('cleaned_dataset.csv', index=False)\n",
    "\n",
    "    # KMeans clusters for sentiment\n",
    "\n",
    "\n",
    "    word_vectors = Word2Vec.load(\"word2vec.model\").wv\n",
    "\n",
    "    model = KMeans(n_clusters=2,\n",
    "                  max_iter=1000,\n",
    "                  random_state=42,\n",
    "                  n_init=50)\n",
    "    model.fit(X=word_vectors.vectors.astype('double'))\n",
    "\n",
    "    word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)\n",
    "\n",
    "    positive_cluster_index = 1\n",
    "    positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
    "    negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]\n",
    "\n",
    "    words = pd.DataFrame(word_vectors.index_to_key)\n",
    "    words.columns = ['words']\n",
    "    words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "    words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "    words.cluster = words.cluster.apply(lambda x: x[0])\n",
    "    words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
    "    words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "    words['sentiment_coeff'] = words.closeness_score * words.cluster_value\n",
    "\n",
    "    words[['words', 'sentiment_coeff']].to_csv('sentiment_dictionary.csv', index=False)\n",
    "\n",
    "    #Labelling data\n",
    "\n",
    "    final_file = pd.read_csv('cleaned_dataset.csv')\n",
    "    sentiment_map = pd.read_csv('sentiment_dictionary.csv')\n",
    "    sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))\n",
    "\n",
    "    file_weighting = final_file.copy()\n",
    "    tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "    tfidf.fit(file_weighting.title)\n",
    "    features = pd.Series(tfidf.get_feature_names_out())\n",
    "    transformed = tfidf.transform(file_weighting.title)\n",
    "\n",
    "    replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)\n",
    "\n",
    "    replaced_closeness_scores = file_weighting.title.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))\n",
    "\n",
    "    replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.title, file_weighting.rate]).T\n",
    "    replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence', 'sentiment']\n",
    "    replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "    replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
    "    replacement_df['sentiment'] = [1 if i==1 else 0 for i in replacement_df.sentiment]\n",
    "\n",
    "    predictedList.append(replacement_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SbYa4sYXXHlV"
   },
   "outputs": [],
   "source": [
    "merge = pd.concat(predictedList)\n",
    "\n",
    "tempList = []\n",
    "tempList.append(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "I89DYuiqRwYt"
   },
   "outputs": [],
   "source": [
    "listTwoElems = []\n",
    "\n",
    "for elem in tempList:\n",
    "  listTwoElems.append(elem[['sentence', 'prediction']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-3HkT9eVGKd",
    "outputId": "fe82f274-7291-4611-88ce-e2aafa1fb507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               sentence  prediction\n",
      "0     breathless kenny_g i really_hate quite_a few o...           1\n",
      "1     i just_discovered them i cannot stop_listening...           0\n",
      "2     that is one_of the several reasons i posted th...           0\n",
      "3                                           oh heck yes           1\n",
      "4                          sam_wilkes live on the green           0\n",
      "...                                                 ...         ...\n",
      "2732  black_sabbath iron_maiden slayer slipknot and ...           1\n",
      "2733                  songs about life going in circles           0\n",
      "2734  more of the_latter but has some heavier elemen...           1\n",
      "2735  im typically not into_tech death but my old ro...           1\n",
      "2736  i_saw revocation with support from goatwhore a...           0\n",
      "\n",
      "[2737 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(listTwoElems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "nL4op2w1dKan",
    "outputId": "157e2c46-9553-4a6d-f6f9-633355f4a4d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breathless kenny_g i really_hate quite_a few of his albums but this_one is special</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i just_discovered them i cannot stop_listening my_fav musician is sergio mendes so i recognize many of the songs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is one_of the several reasons i posted this someone told_me that there_are some british documentaries on_youtube that are superior to this series i_suppose it is on me to_explore which_ones are best</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oh heck yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sam_wilkes live on the green</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>black_sabbath iron_maiden slayer slipknot and some motley crue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>songs about life going in circles</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>more of the_latter but has some heavier elements i much prefer beyond hypothermia/uyhs era cave in but i like this new_album quite_a bit its super long though around 80 minutes i_think</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>im typically not into_tech death but my old room mate got_me into revocation which then led me to archspire and_inferi the new archspire album is absolutely nuts i really love how theres still an_actual song amongst_the crazy technicalities with that said_they end_up having_a lot_of similar sounding songs but when i listen_to archspire its for exactly that style cant_wait to_see them and_inferi in may</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>i_saw revocation with support from goatwhore alluvial and creeping_death on tuesday in dublin never had heard of goatwhore and they_were the most entertaining band of the night every_band killed_it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2737 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                  sentence  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                       breathless kenny_g i really_hate quite_a few of his albums but this_one is special   \n",
       "1                                                                                                                                                                                                                                                                                                         i just_discovered them i cannot stop_listening my_fav musician is sergio mendes so i recognize many of the songs   \n",
       "2                                                                                                                                                                                                              that is one_of the several reasons i posted this someone told_me that there_are some british documentaries on_youtube that are superior to this series i_suppose it is on me to_explore which_ones are best   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                              oh heck yes   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                             sam_wilkes live on the green   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "2732                                                                                                                                                                                                                                                                                                                                                        black_sabbath iron_maiden slayer slipknot and some motley crue   \n",
       "2733                                                                                                                                                                                                                                                                                                                                                                                     songs about life going in circles   \n",
       "2734                                                                                                                                                                                                                              more of the_latter but has some heavier elements i much prefer beyond hypothermia/uyhs era cave in but i like this new_album quite_a bit its super long though around 80 minutes i_think   \n",
       "2735  im typically not into_tech death but my old room mate got_me into revocation which then led me to archspire and_inferi the new archspire album is absolutely nuts i really love how theres still an_actual song amongst_the crazy technicalities with that said_they end_up having_a lot_of similar sounding songs but when i listen_to archspire its for exactly that style cant_wait to_see them and_inferi in may   \n",
       "2736                                                                                                                                                                                                                 i_saw revocation with support from goatwhore alluvial and creeping_death on tuesday in dublin never had heard of goatwhore and they_were the most entertaining band of the night every_band killed_it   \n",
       "\n",
       "      prediction  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  \n",
       "...          ...  \n",
       "2732           1  \n",
       "2733           0  \n",
       "2734           1  \n",
       "2735           1  \n",
       "2736           0  \n",
       "\n",
       "[2737 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "  display(listTwoElems[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VHn2YRSPo6Fp"
   },
   "source": [
    "BERT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6qE4JiZo9dL",
    "outputId": "7303c367-c8d3-472c-acf2-e866e40375a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.28.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (4.28.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from transformers==4.28.0) (6.0)\n",
      "Requirement already satisfied: filelock in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from transformers==4.28.0) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from transformers==4.28.0) (22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from transformers==4.28.0) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from transformers==4.28.0) (0.14.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from transformers==4.28.0) (0.11.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from transformers==4.28.0) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from transformers==4.28.0) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from transformers==4.28.0) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2022.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.28.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.28.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.28.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests->transformers==4.28.0) (2.0.4)\n",
      "Requirement already satisfied: datasets in /home/piotrzab/anaconda3/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (0.14.1)\n",
      "Requirement already satisfied: pandas in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: aiohttp in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: packaging in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: xxhash in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: multiprocess in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: filelock in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.28.0\n",
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "DgL6NFrQo_vi",
    "outputId": "5eada178-da8d-4cf3-a386-ec1e9e2fcc68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.28.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "EGmkL3hUpFXW",
    "outputId": "e30dc940-6be0-41e5-a59f-2bc1fa534334"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_550078/25399030.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.rename(columns={'prediction':'label'}, inplace=True)\n",
      "/tmp/ipykernel_550078/25399030.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.rename(columns={'sentence':'text'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>pat_metheny bright_size life on ecm records</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>crypt of ice is that album i know is good but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>oh_yeah love this guys truly rednecks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>pretty_sure thats the_90s remake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>speaking of herbie yesterday i heard a version...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "644         pat_metheny bright_size life on ecm records      0\n",
       "2433  crypt of ice is that album i know is good but ...      0\n",
       "2646              oh_yeah love this guys truly rednecks      1\n",
       "270                    pretty_sure thats the_90s remake      1\n",
       "288   speaking of herbie yesterday i heard a version...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = listTwoElems[0]\n",
    "data.rename(columns={'prediction':'label'}, inplace=True)\n",
    "data.rename(columns={'sentence':'text'}, inplace=True)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nSiQlFu7q8nA"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset_ = Dataset.from_pandas(data)\n",
    "dataset = dataset_.train_test_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qBv18HU4pn6K"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "g9Wdb1oIpoJl"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "fb136be8ff17493ea73788766135a0bd",
      "56dc1fcee7fa4f7b9606cda890df1ea6",
      "d44efe3f0e4b42328880b1d08eaa9107",
      "221807ef6e8c4b38a66c4a63b3c6e6d9",
      "6b7531db2bda4c98bdd5c38f3607f34f",
      "d1986e0a60b3487bb70ee550ab471974",
      "706c584f9865456a8d3dcc4f8240e6ac",
      "6709bb2f15194747b881406404da6303",
      "6562b58374bd43d99cd436b0e8c0577c",
      "cb10fa56552b4a02ae0b9ac7e1215289",
      "9266ccde0c8342ec8610bf4a2fd755fd",
      "9f6f1dc3b2c444f7b8937c76086050d7",
      "569156b8a1044aa2800daf571c838a44",
      "d0df3c7dc3f747efa9daa96465a33ba8",
      "856e77df759c4975b6dbe7fc4021fd0c",
      "6ce03aaa3bcd423fae9677d8829ec278",
      "7277af905c2c478eaa3554c35d99817e",
      "a8f2aeb966d54d73adc413f06d1074f0",
      "76dfbe1f2bb14e6786736bf64b672bab",
      "a92db699e5a446fe9a03974f9f810c8b",
      "98828b48aa18438495b8e65db629c64d",
      "7ab9d440c010443593d7fc0c7ecb77ec"
     ]
    },
    "id": "is3GQvUwprxt",
    "outputId": "bfbd7a53-3658-4803-adca-6d5d0e55e2b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process(x):\n",
    "  return tokenizer(x['text'])\n",
    "\n",
    "train_ds = dataset['train'].map(process)\n",
    "test_ds = dataset['test'].map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvgD9CjppuLV",
    "outputId": "d013f6b2-b4a1-487d-98e5-34c741c5916c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = 2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_6BmyAMpwJQ",
    "outputId": "91209210-7db1-4daa-f133-cb658217c96b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: accelerate in /home/piotrzab/anaconda3/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from accelerate) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: pyyaml in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: psutil in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from accelerate) (22.0)\n",
      "Requirement already satisfied: typing_extensions in /home/piotrzab/anaconda3/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EzwJqleqpyTy"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f'{model_checkpoint}_sentiment_analysis',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    num_train_epochs = 5,\n",
    "    weight_decay = 0.01,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "47Ejkd-dpz8i"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_550078/2777850806.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('glue', 'sst2')\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric('glue', 'sst2')\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "  logits, labels = eval_preds\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "adNfOcL5p1VN"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "QeSix--ip3el",
    "outputId": "40a6d280-9ec7-4cdc-ea68-31910a907dde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 03:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6170973777770996,\n",
       " 'eval_accuracy': 1.0,\n",
       " 'eval_runtime': 0.066,\n",
       " 'eval_samples_per_second': 15.155,\n",
       " 'eval_steps_per_second': 15.155}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate([train_ds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "GDOsY1qjp5Ks",
    "outputId": "2936fde5-14b7-46a5-816f-8243127c3c9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotrzab/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 17:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692657</td>\n",
       "      <td>0.521898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.691940</td>\n",
       "      <td>0.551095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.562044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684854</td>\n",
       "      <td>0.580292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681816</td>\n",
       "      <td>0.580292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.6762546539306641, metrics={'train_runtime': 1079.321, 'train_samples_per_second': 11.41, 'train_steps_per_second': 0.093, 'total_flos': 361669115180544.0, 'train_loss': 0.6762546539306641, 'epoch': 5.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the accuracy is around 55%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "221807ef6e8c4b38a66c4a63b3c6e6d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb10fa56552b4a02ae0b9ac7e1215289",
      "placeholder": "​",
      "style": "IPY_MODEL_9266ccde0c8342ec8610bf4a2fd755fd",
      "value": " 665/700 [00:00&lt;00:00, 1227.04 examples/s]"
     }
    },
    "569156b8a1044aa2800daf571c838a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7277af905c2c478eaa3554c35d99817e",
      "placeholder": "​",
      "style": "IPY_MODEL_a8f2aeb966d54d73adc413f06d1074f0",
      "value": "Map:  95%"
     }
    },
    "56dc1fcee7fa4f7b9606cda890df1ea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1986e0a60b3487bb70ee550ab471974",
      "placeholder": "​",
      "style": "IPY_MODEL_706c584f9865456a8d3dcc4f8240e6ac",
      "value": "Map:  95%"
     }
    },
    "6562b58374bd43d99cd436b0e8c0577c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6709bb2f15194747b881406404da6303": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b7531db2bda4c98bdd5c38f3607f34f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "6ce03aaa3bcd423fae9677d8829ec278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "706c584f9865456a8d3dcc4f8240e6ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7277af905c2c478eaa3554c35d99817e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76dfbe1f2bb14e6786736bf64b672bab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ab9d440c010443593d7fc0c7ecb77ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "856e77df759c4975b6dbe7fc4021fd0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98828b48aa18438495b8e65db629c64d",
      "placeholder": "​",
      "style": "IPY_MODEL_7ab9d440c010443593d7fc0c7ecb77ec",
      "value": " 74/78 [00:00&lt;00:00, 358.19 examples/s]"
     }
    },
    "9266ccde0c8342ec8610bf4a2fd755fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98828b48aa18438495b8e65db629c64d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f6f1dc3b2c444f7b8937c76086050d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_569156b8a1044aa2800daf571c838a44",
       "IPY_MODEL_d0df3c7dc3f747efa9daa96465a33ba8",
       "IPY_MODEL_856e77df759c4975b6dbe7fc4021fd0c"
      ],
      "layout": "IPY_MODEL_6ce03aaa3bcd423fae9677d8829ec278"
     }
    },
    "a8f2aeb966d54d73adc413f06d1074f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a92db699e5a446fe9a03974f9f810c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cb10fa56552b4a02ae0b9ac7e1215289": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0df3c7dc3f747efa9daa96465a33ba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76dfbe1f2bb14e6786736bf64b672bab",
      "max": 78,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a92db699e5a446fe9a03974f9f810c8b",
      "value": 78
     }
    },
    "d1986e0a60b3487bb70ee550ab471974": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d44efe3f0e4b42328880b1d08eaa9107": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6709bb2f15194747b881406404da6303",
      "max": 700,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6562b58374bd43d99cd436b0e8c0577c",
      "value": 700
     }
    },
    "fb136be8ff17493ea73788766135a0bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56dc1fcee7fa4f7b9606cda890df1ea6",
       "IPY_MODEL_d44efe3f0e4b42328880b1d08eaa9107",
       "IPY_MODEL_221807ef6e8c4b38a66c4a63b3c6e6d9"
      ],
      "layout": "IPY_MODEL_6b7531db2bda4c98bdd5c38f3607f34f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
